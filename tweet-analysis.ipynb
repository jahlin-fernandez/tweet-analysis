{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMS W1002 Computing in Context: Computing in the humanities\n",
    "## Project 1: Tweets\n",
    "## Due November 12th at 11:59PM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you will develop tools for performing sentiment analysis on a database of tweets from across the country. When the project is complete you should be able to estimate the sentiment of tweets filtered by content.\n",
    "\n",
    "There are 4 files provided here: http://www.cs.columbia.edu/~cannon/tweet_data/\n",
    "\n",
    "1. `all_tweets.txt`    is the large collection of tweets \n",
    "2. `some_tweets.txt`   is a subset of all_tweets that's more manageable to prototype on\n",
    "3. `sentiments.csv`    a csv with word sentiment values\n",
    "4. `zips.csv` (not required, see below)\n",
    "\n",
    "We will go over the format of each of these files in class. \n",
    "\n",
    "**Tweets:**\n",
    "We will represent a tweet using a Python dictionary with the following entries: \n",
    "* text: a string, the text of the tweet all in lowercase\n",
    "* time: a datetime object, date and time of the tweet\n",
    "* latitude: a float, the latitude of the tweet's location\n",
    "* longitude: a float, the longitude of the tweet's location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1** Write a function called `make_tweets` that takes as input a file name and returns a list of dictionaries. Each dictionary corresponds to a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### worked with Antonio Cerros and Celena Dong\n",
    "\n",
    "def make_tweets(file):\n",
    "    import datetime\n",
    "    dics = []\n",
    "    \n",
    "    with open(file, 'r', encoding = 'utf8') as f:\n",
    "        line = f.readline()\n",
    "        while line != '': \n",
    "                \n",
    "            l = line.split('\\t')\n",
    "            \n",
    "            # determine if next line should be a new dic\n",
    "            while (len(l) <4):\n",
    "                if len(l)<2:\n",
    "                    dic['text'] = text + ' ' + line.rstrip('\\n')\n",
    "                line = f.readline()\n",
    "                l = line.split('\\t')\n",
    "            \n",
    "            # find the latitude and longitude\n",
    "            sub_list = l[0].rstrip(\"]\")\n",
    "            sub_list = sub_list.lstrip(\"[\")\n",
    "            sub_list = sub_list.split(\",\")\n",
    "\n",
    "            latitude = float(sub_list[0])\n",
    "            longitude = float((sub_list[1]).lstrip(\" \"))\n",
    "            \n",
    "            # find the datetime\n",
    "            sub_list2 = l[2].split(\" \")\n",
    "            dates = sub_list2[0].split('-')\n",
    "            times = sub_list2[1].split(':')\n",
    "            date = datetime.datetime(int(dates[0]), int(dates[1]), int(dates[2]), int(times[0]), int(times[1]), int(times[2]))\n",
    "\n",
    "            # find the text\n",
    "            text = l[3].rstrip('\\n')\n",
    "            \n",
    "            # make dic\n",
    "            dic = {'text': text, 'time': date, 'latitude': latitude, 'longitude': longitude}\n",
    "            \n",
    "            # append dic to dics\n",
    "            dics.append(dic)\n",
    "            \n",
    "            # read the next line \n",
    "            line = f.readline()\n",
    "            \n",
    "    return dics\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2** Write a function `add_sentiment` to determine the sentiment of each tweet by taking the average sentiment over all of the words in the tweet. The function should return a new list of tweets where each tweet has a new key '`sentiment`' with numeric value between -1 and 1, or *None* representing the sentiment of the tweet. Note: words without a sentiment do not have sentiment 0. Your function should take as input a list of tweets (dictionaries) together with the name of the sentiment file. Be careful that your function does not alter the original list (no side effects!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### worked with Antonio Cerros\n",
    "def add_sentiment(tweets,filename):\n",
    "    import csv\n",
    "    \n",
    "    # new list\n",
    "    new_tweets = []\n",
    "    puncs = '.,\"!:;/?()&*'\n",
    "    \n",
    "    # take each tweet\n",
    "    for tweet in tweets:\n",
    "            \n",
    "        words = tweet['text']\n",
    "        total_sentiments = 0\n",
    "        count = 0  \n",
    "        \n",
    "        # make sure every word is lowercase and without punctuation\n",
    "        words = words.lower()\n",
    "        words = ''.join(ch for ch in words if ch not in puncs)\n",
    "              \n",
    "   \n",
    "        # open sentiment file\n",
    "        with open(filename, 'r', encoding = 'utf8') as f:\n",
    "            sent_file = csv.reader(f)\n",
    "            answer = False\n",
    "            \n",
    "            for row in sent_file:\n",
    "                sent_word = row[0]\n",
    "                \n",
    "                # different methods for a frase and a single word\n",
    "                if len(sent_word.split()) > 1:\n",
    "                    if sent_word in words:\n",
    "                        answer = True\n",
    "                else:\n",
    "                    word_list = words.split()\n",
    "                    for word in word_list:\n",
    "                        if word == sent_word:\n",
    "                            answer = True\n",
    "            \n",
    "                if answer == True:  \n",
    "                   \n",
    "                    # if the word is in the sentiment file, value = value in sentiment file\n",
    "                    total_sentiments += float(row[1])\n",
    "                    count += 1\n",
    "                    answer = False\n",
    "                            \n",
    "        # create new dictionary with all the info from the previous dictionary, plus the sentiment floating point value\n",
    "        dic = tweet.copy()\n",
    "            \n",
    "        # if none of the words had a sentiment, the sentiment is None\n",
    "        if count == 0:\n",
    "            dic['sentiment'] = None\n",
    "        else:\n",
    "            \n",
    "            # take the average sentiment of all the words that have a sentiment\n",
    "            dic['sentiment'] = total_sentiments / count\n",
    "            \n",
    "        # add dictionary to list\n",
    "        new_tweets.append(dic)\n",
    "            \n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**  Write a function called `tweet_filter` that will return a new list of tweets filtered by the content of the tweet text. The input for this function should be a list of tweets and a list of words (strings). The function should return a list of tweets that each include *all* of the words in the word list ignoring case and punctuation. Note: Since you are not changing the tweets, as long as the returned list is new, you don't have to worry about side-effects on the tweets here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_filter(tweets, words):\n",
    "    \n",
    "    # empty list\n",
    "    filtered = []\n",
    "    puncs = set('.,\"!:;/?()&*')\n",
    "    \n",
    "    # get each tweet\n",
    "    for tweet in tweets:\n",
    "        answer = True\n",
    "        \n",
    "        # remove all punctuation\n",
    "        text = tweet['text']\n",
    "        text = text.lower()\n",
    "        text = ''.join(ch for ch in text if ch not in puncs)\n",
    "            \n",
    "        # check to see if the words are in the tweet\n",
    "        for word in words:\n",
    "            if len(word.split(' ')) > 1:\n",
    "                if word not in text:\n",
    "                    answer = False\n",
    "            else:\n",
    "                tweet_text = text.split(' ')\n",
    "                if word not in tweet_text:\n",
    "                    answer = False\n",
    "                \n",
    "        # if answer = true, add the tweet to the list \n",
    "        if answer == True:\n",
    "            filtered.append(tweet)\n",
    "                        \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4** Use your work above and below to answer the following questions:\n",
    "1. What is the average sentiment of tweets containing the word 'beer'\n",
    "2. What is the average sentiment of tweets containing the word 'coffee'\n",
    "3. Consider the average sentiment of the tweets containing the words 'beer', 'movie','coffee', and 'work'. Which word leads to a list of tweets with the lowest average sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the code you wrote for Problem 4 here\n",
    "\n",
    "# create a function to find the average sentiment\n",
    "def avg_sentiment(tweet_file, sent_file, words):\n",
    "    sentiment = 0\n",
    "    tweet_list = make_tweets(tweet_file)\n",
    "    \n",
    "    # get a list of all tweets with the words in them\n",
    "    sub_list = tweet_filter(tweet_list, words)\n",
    "    \n",
    "    # includng the sentiments\n",
    "    sub_list = add_sentiment(sub_list, sent_file)\n",
    "    \n",
    "    # get the sum\n",
    "    for tweet in sub_list:\n",
    "        if tweet['sentiment'] != None:\n",
    "            sentiment += tweet['sentiment']\n",
    "    \n",
    "    if len(sub_list) != 0 and sentiment!= None:\n",
    "        \n",
    "        # return the average\n",
    "        return sentiment / len(sub_list)\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220\n",
      "0.0387132891820392\n",
      "4571\n",
      "0.06249799208606364\n",
      "3084\n",
      "0.07889053203425771\n",
      "17480\n",
      "-0.01940605305465581\n"
     ]
    }
   ],
   "source": [
    "print(avg_sentiment('all_tweets.txt', 'sentiments.csv', ['beer']))\n",
    "print(avg_sentiment('all_tweets.txt', 'sentiments.csv', ['coffee']))\n",
    "print(avg_sentiment('all_tweets.txt', 'sentiments.csv', ['movie']))\n",
    "print(avg_sentiment('all_tweets.txt', 'sentiments.csv', ['work']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the answers to problem 4 here:\n",
    "\n",
    "1. Average sentiment: 0.0387133\n",
    "2. Average sentiment: 0.0624979\n",
    "3. Lowest average sentiment: 'work'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the aspiring hacker: *(not for credit)*\n",
    "\n",
    "Notice you have geographical information here. How can you use the longitude and latitude information together with the zips.csv file to allow for queries that are filtered by location as well as message content? Implement such a mechanism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
